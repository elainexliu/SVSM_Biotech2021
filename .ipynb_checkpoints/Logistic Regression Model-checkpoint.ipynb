{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix, classification_report,f1_score,accuracy_score,precision_score,recall_score\n",
    "from sklearn.model_selection import KFold, LeaveOneOut,cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from time import time\n",
    "import timeit #imports timeit module\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import random\n",
    "random.seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index_name ogAA_letter  positionAA_num mutAA_letter  iso_point ogAA_char  \\\n",
      "0      A171T           A             171            T       6.76         n   \n",
      "1      D140N           D             140            N       7.15         -   \n",
      "2      D109H           D             109            H       7.18         -   \n",
      "3      D109A           D             109            A       7.15         -   \n",
      "4       P20S           P              20            S       6.76         P   \n",
      "\n",
      "  mutAA_char  deldel_G1  solv_area  deldel_G2  deldel_G3  evo_age  pdel  \\\n",
      "0          l      -0.47       85.3  -0.550085  -0.005249      324  0.50   \n",
      "1          l      -0.96       59.0  -1.864259  -0.180476      750  0.74   \n",
      "2        H,+      -0.42       65.2  -0.661944  -0.509662      750  0.74   \n",
      "3          n      -0.11       65.2  -0.550471  -0.670734      750  0.74   \n",
      "4          l      -0.78       35.9  -0.703610  -0.456211      750  0.74   \n",
      "\n",
      "  positive_negative  \n",
      "0          positive  \n",
      "1          positive  \n",
      "2          positive  \n",
      "3          positive  \n",
      "4          positive  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Cataract Data 1.3.csv', na_values='?').dropna()\n",
    "# df = pd.read_csv('Cataract Data 1.3.csv', index_col=0, parse_dates=True)\n",
    "print(df.head())\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ML_logistic_regression_summaries(Vars):\n",
    "    \n",
    "    #define X and y variables\n",
    "    X = df.loc[:, Vars] \n",
    "    y = df.loc[:, \"positive_negative\"] \n",
    "    \n",
    "    #set the model\n",
    "    model = LogisticRegression(solver= 'liblinear', class_weight = 'balanced')\n",
    "\n",
    "    #set the CV\n",
    "    kf = LeaveOneOut()\n",
    "    \n",
    "    #start timer for getting elapsed time\n",
    "    from time import time\n",
    "    import timeit #imports timeit module\n",
    "    start_time = timeit.default_timer() #defines start time so computational time can be calculated\n",
    "\n",
    "    #define lists\n",
    "    acc_score = [];\n",
    "    Truth = [];\n",
    "    Output = [];\n",
    "\n",
    "    #loop though each fold (so 40 times in our case)\n",
    "    for train_index , test_index in kf.split(df):\n",
    "        \n",
    "        #split the data\n",
    "        X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = .25, shuffle=True)\n",
    "\n",
    "        #print(X_train); print(X_test); print(y_train); print(y_test)\n",
    "        \n",
    "        #fit the model\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        #preduct values\n",
    "        pred_values = model.predict(X_test)\n",
    "\n",
    "        #append the accuracy score\n",
    "        acc = accuracy_score(pred_values, y_test)\n",
    "        acc_score.append(acc)\n",
    "\n",
    "        #add to the truth and output\n",
    "        Truth.extend(y_test.values.reshape(y_test.shape[0])); ## it is a list\n",
    "        Output.extend(pred_values); ## it is a list  \n",
    "        \n",
    "\n",
    " \n",
    "    #determine the time elapesed\n",
    "    elapsed = timeit.default_timer() - start_time #gives total computation time\n",
    "\n",
    "    #return the dataframe\n",
    "    test = pd.DataFrame(data={\"Predicted:\": Output, \"Real\": Truth})\n",
    "    \n",
    "    #set output to a dataframe\n",
    "    dfOutput = pd.DataFrame(data={\"X Variable(s)\": [Vars,],\n",
    "                                  \"Avg Accuracy\": [np.mean(acc_score),],\n",
    "                                  \"SD of Accuracy\": [np.std(acc_score),],\n",
    "                                  \"Sensitivity\": [recall_score(Truth,Output,pos_label=\"negative\"),],\n",
    "                                  \"Precision\": [precision_score(Truth,Output,pos_label=\"negative\"),],\n",
    "                                  \"F1-Score\": [f1_score(Truth,Output,pos_label=\"negative\"),],\n",
    "                                  \"Runtime\": [elapsed,],\n",
    "                                  \"Confusion_Matrix\": str(confusion_matrix(Truth,Output))}) #,\"Real Specificity\": [1,]\n",
    "    #return output\n",
    "    return dfOutput\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X Variable(s)</th>\n",
       "      <th>Avg Accuracy</th>\n",
       "      <th>SD of Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Confusion_Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[pdel, iso_point]</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.161245</td>\n",
       "      <td>0.861423</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.112095</td>\n",
       "      <td>[[230  37]\\n [ 23 110]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       X Variable(s)  Avg Accuracy  SD of Accuracy  Sensitivity  Precision  \\\n",
       "0  [pdel, iso_point]          0.85        0.161245     0.861423   0.909091   \n",
       "\n",
       "   F1-Score   Runtime         Confusion_Matrix  \n",
       "0  0.884615  0.112095  [[230  37]\\n [ 23 110]]  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_logistic_regression_summaries([\"pdel\",\"iso_point\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X Variable(s)</th>\n",
       "      <th>Avg Accuracy</th>\n",
       "      <th>SD of Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Confusion_Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[pdel, iso_point]</td>\n",
       "      <td>0.8475</td>\n",
       "      <td>0.130360</td>\n",
       "      <td>0.844106</td>\n",
       "      <td>0.917355</td>\n",
       "      <td>0.879208</td>\n",
       "      <td>0.132654</td>\n",
       "      <td>[[222  41]\\n [ 20 117]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[pdel, deldel_G3]</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.543210</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.112460</td>\n",
       "      <td>[[132 111]\\n [ 33 124]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[iso_point, deldel_G3]</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.154839</td>\n",
       "      <td>0.593023</td>\n",
       "      <td>0.621951</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.132087</td>\n",
       "      <td>[[153 105]\\n [ 93  49]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            X Variable(s)  Avg Accuracy  SD of Accuracy  Sensitivity  \\\n",
       "0       [pdel, iso_point]        0.8475        0.130360     0.844106   \n",
       "0       [pdel, deldel_G3]        0.6400        0.130000     0.543210   \n",
       "0  [iso_point, deldel_G3]        0.5050        0.154839     0.593023   \n",
       "\n",
       "   Precision  F1-Score   Runtime         Confusion_Matrix  \n",
       "0   0.917355  0.879208  0.132654  [[222  41]\\n [ 20 117]]  \n",
       "0   0.800000  0.647059  0.112460  [[132 111]\\n [ 33 124]]  \n",
       "0   0.621951  0.607143  0.132087  [[153 105]\\n [ 93  49]]  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_variables_logistic(inputList):\n",
    "    outputList = []\n",
    "\n",
    "    for i in inputList:\n",
    "        outputList.append(ML_logistic_regression_summaries(i))\n",
    "\n",
    "    outputList = pd.concat(outputList)\n",
    "\n",
    "    return outputList\n",
    "\n",
    "compare_variables_logistic([[\"pdel\",\"iso_point\"], [\"pdel\",\"deldel_G3\"], [\"iso_point\", \"deldel_G3\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X Variable(s)</th>\n",
       "      <th>Avg Accuracy</th>\n",
       "      <th>SD of Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Confusion_Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[pdel, iso_point]</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.058949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.935714</td>\n",
       "      <td>0.96679</td>\n",
       "      <td>0.430984</td>\n",
       "      <td>[[262   0]\\n [ 18 120]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       X Variable(s)  Avg Accuracy  SD of Accuracy  Sensitivity  Precision  \\\n",
       "0  [pdel, iso_point]         0.955        0.058949          1.0   0.935714   \n",
       "\n",
       "   F1-Score   Runtime         Confusion_Matrix  \n",
       "0   0.96679  0.430984  [[262   0]\\n [ 18 120]]  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def ML_KNN_summaries(Vars):\n",
    "    \n",
    "    #define X and y variables\n",
    "    X = df.loc[:, Vars] \n",
    "    y = df.loc[:, \"positive_negative\"] \n",
    "    \n",
    "    #standardize X --> Elaine doesn't think this is the right place to do so, so check the for loop\n",
    "#     scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "#     X_scaled = scaler.transform(X_train)\n",
    "#     print(X_scaled)    \n",
    "    \n",
    "    #set the model\n",
    "    model = neighbors.KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "    #set the CV\n",
    "    kf = LeaveOneOut()\n",
    "    \n",
    "    #start timer for getting elapsed time\n",
    "    from time import time\n",
    "    import timeit #imports timeit module\n",
    "    start_time = timeit.default_timer() #defines start time so computational time can be calculated\n",
    "\n",
    "    #define lists\n",
    "    acc_score = [];\n",
    "    Truth = [];\n",
    "    Output = [];\n",
    "\n",
    "    #loop though each fold (so 40 times in our case)\n",
    "    for train_index , test_index in kf.split(df):\n",
    "        \n",
    "        #split the data\n",
    "        X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = .25, shuffle=True)\n",
    "\n",
    "        #print(X_train); print(X_test); print(y_train); print(y_test)\n",
    "        \n",
    "        #standardizing the X (you change line 44 to model.fit(X_scaled, y_train))\n",
    "#         scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "#         X_scaled = scaler.transform(X_train)\n",
    "        \n",
    "        #fit the model\n",
    "        model.fit(X,y_train)\n",
    "        \n",
    "        #preduct values\n",
    "        pred_values = model.predict(X_test)\n",
    "\n",
    "        #append the accuracy score\n",
    "        acc = accuracy_score(pred_values, y_test)\n",
    "        acc_score.append(acc)\n",
    "\n",
    "        #add to the truth and output\n",
    "        Truth.extend(y_test.values.reshape(y_test.shape[0])); ## it is a list\n",
    "        Output.extend(pred_values); ## it is a list  \n",
    "        \n",
    "\n",
    " \n",
    "    #determine the time elapesed\n",
    "    elapsed = timeit.default_timer() - start_time #gives total computation time\n",
    "\n",
    "    #return the dataframe\n",
    "    #test = pd.DataFrame(data={\"Predicted:\": Output, \"Real\": Truth})\n",
    "    \n",
    "    #set output to a dataframe\n",
    "    dfOutput = pd.DataFrame(data={\"X Variable(s)\": [Vars,],\n",
    "                                  \"Avg Accuracy\": [np.mean(acc_score),],\n",
    "                                  \"SD of Accuracy\": [np.std(acc_score),],\n",
    "                                  \"Sensitivity\": [recall_score(Truth,Output,pos_label=\"negative\"),],\n",
    "                                  \"Precision\": [precision_score(Truth,Output,pos_label=\"negative\"),],\n",
    "                                  \"F1-Score\": [f1_score(Truth,Output,pos_label=\"negative\"),],\n",
    "                                  \"Runtime\": [elapsed,],\n",
    "                                  \"Confusion_Matrix\": str(confusion_matrix(Truth,Output))}) #,\"Real Specificity\": [1,]\n",
    "    #return output\n",
    "    #test = pd.DataFrame(data={\"Predicted:\": Output, \"Real\": Truth})\n",
    "    return dfOutput\n",
    "\n",
    "ML_KNN_summaries([\"pdel\",\"iso_point\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
