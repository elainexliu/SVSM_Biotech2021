{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab on K-Nearest Neighbors is a python adaptation of p. 163-167 of \"Introduction to Statistical Learning with Applications in R\" by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani. Originally adapted by Jordi Warmenhoven (github.com/JWarmenhoven/ISLR-python), modified by R. Jordan Crouser at Smith College for SDS293: Machine Learning (Spring 2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6.5: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will perform KNN clustering on the `Smarket` dataset from `ISLR`. This data set consists of percentage returns for the S&P 500 stock index over 1,250 days, from the\n",
    "beginning of 2001 until the end of 2005. \n",
    "\n",
    "For each date, we have recorded the percentage returns for each of the five previous trading days (`Lag1` through `Lag5`). \n",
    "\n",
    "We have also recorded:\n",
    "- `Volume` (the number of shares traded on the previous day, in billions)\n",
    "- `Today` (the percentage return on the date in question) \n",
    "- `Direction` (whether the market was `Up` or `Down` on this date). \n",
    "\n",
    "We can use the `head()` function to look at the first few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ogAA_letter</th>\n",
       "      <th>positionAA_num</th>\n",
       "      <th>mutAA_letter</th>\n",
       "      <th>positive_negative</th>\n",
       "      <th>iso_point</th>\n",
       "      <th>ogAA_char</th>\n",
       "      <th>mutAA_char</th>\n",
       "      <th>deldel_G1</th>\n",
       "      <th>solv_area</th>\n",
       "      <th>deldel_G2</th>\n",
       "      <th>deldel_G3</th>\n",
       "      <th>evo_age</th>\n",
       "      <th>pdel</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A171T</th>\n",
       "      <td>A</td>\n",
       "      <td>171</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>6.76</td>\n",
       "      <td>n</td>\n",
       "      <td>l</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>85.3</td>\n",
       "      <td>-0.550085</td>\n",
       "      <td>-0.005249</td>\n",
       "      <td>324</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D140N</th>\n",
       "      <td>D</td>\n",
       "      <td>140</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>7.15</td>\n",
       "      <td>-</td>\n",
       "      <td>l</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-1.864259</td>\n",
       "      <td>-0.180476</td>\n",
       "      <td>750</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D109H</th>\n",
       "      <td>D</td>\n",
       "      <td>109</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>7.18</td>\n",
       "      <td>-</td>\n",
       "      <td>H,+</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>65.2</td>\n",
       "      <td>-0.661944</td>\n",
       "      <td>-0.509662</td>\n",
       "      <td>750</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D109A</th>\n",
       "      <td>D</td>\n",
       "      <td>109</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>7.15</td>\n",
       "      <td>-</td>\n",
       "      <td>n</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>65.2</td>\n",
       "      <td>-0.550471</td>\n",
       "      <td>-0.670734</td>\n",
       "      <td>750</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P20S</th>\n",
       "      <td>P</td>\n",
       "      <td>20</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>6.76</td>\n",
       "      <td>P</td>\n",
       "      <td>l</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>35.9</td>\n",
       "      <td>-0.703610</td>\n",
       "      <td>-0.456211</td>\n",
       "      <td>750</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ogAA_letter  positionAA_num mutAA_letter  positive_negative  \\\n",
       "index_name                                                               \n",
       "A171T                A             171            T                  1   \n",
       "D140N                D             140            N                  1   \n",
       "D109H                D             109            H                  1   \n",
       "D109A                D             109            A                  1   \n",
       "P20S                 P              20            S                  1   \n",
       "\n",
       "            iso_point ogAA_char mutAA_char  deldel_G1  solv_area  deldel_G2  \\\n",
       "index_name                                                                    \n",
       "A171T            6.76         n          l      -0.47       85.3  -0.550085   \n",
       "D140N            7.15         -          l      -0.96       59.0  -1.864259   \n",
       "D109H            7.18         -        H,+      -0.42       65.2  -0.661944   \n",
       "D109A            7.15         -          n      -0.11       65.2  -0.550471   \n",
       "P20S             6.76         P          l      -0.78       35.9  -0.703610   \n",
       "\n",
       "            deldel_G3  evo_age  pdel  \n",
       "index_name                            \n",
       "A171T       -0.005249      324  0.50  \n",
       "D140N       -0.180476      750  0.74  \n",
       "D109H       -0.509662      750  0.74  \n",
       "D109A       -0.670734      750  0.74  \n",
       "P20S        -0.456211      750  0.74  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Cataract Data 1.2.csv', index_col=0, parse_dates = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we're going to try to predict `Direction` using percentage returns from the previous two days (`Lag1` and `Lag2`). We'll build our model using the `KNeighborsClassifier()` function, which is part of the\n",
    "`neighbors` submodule of SciKitLearn (`sklearn`). We'll also grab a couple of useful tools from the `metrics` submodule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function works rather differently from the other model-fitting\n",
    "functions that we have encountered thus far. Rather than a two-step\n",
    "approach in which we first fit the model and then we use the model to make\n",
    "predictions, `knn()` forms predictions using a single command. The function\n",
    "requires four inputs.\n",
    "   1. A matrix containing the predictors associated with the training data,\n",
    "labeled `X_train` below.\n",
    "   2. A matrix containing the predictors associated with the test data, labeled `X_test` below.\n",
    "   3. A vector containing the class labels for the training observations,\n",
    "labeled `Y_train` below.\n",
    "   4. A value for `K`, the number of nearest neighbors to be used by the\n",
    "classifier.\n",
    "\n",
    "We'll first create a vector corresponding to the observations from 2001 through 2004, which we'll use to train the model. We will then use this vector to create a held out data set of observations from 2005 on which we will test. We'll also pull out our training and test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[:'K150R'][['deldel_G1','pdel']]\n",
    "y_train = df[:'K150R']['positive_negative']\n",
    "\n",
    "X_test = df['Q151A':][['deldel_G1','pdel']]\n",
    "y_test = df['Q151A':]['positive_negative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the `neighbors.KNeighborsClassifier()` function can be used to predict the market’s movement for\n",
    "the dates in 2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 1)\n",
    "model_knn = knn.fit(X_train, y_train)\n",
    "pred = model_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `confusion_matrix()` function can be used to produce a **confusion matrix** in order to determine how many observations were correctly or incorrectly classified. The `classification_report()` function gives us some summary statistics on the classifier's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0]\n",
      " [1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.800     0.889         5\n",
      "           1      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.800         5\n",
      "   macro avg      0.500     0.400     0.444         5\n",
      "weighted avg      1.000     0.800     0.889         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eliu0\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results using $K = 1$ are not very good, since only 50% of the observations\n",
    "are correctly predicted. Of course, it may be that $K = 1$ results in an\n",
    "overly flexible fit to the data. Below, we repeat the analysis using $K = 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0]\n",
      " [1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.800     0.889         5\n",
      "           1      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.800         5\n",
      "   macro avg      0.500     0.400     0.444         5\n",
      "weighted avg      1.000     0.800     0.889         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eliu0\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results have improved slightly. Try looping through a few other $K$ values to see if you can get any further improvement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k is 1\n",
      "[[4 0]\n",
      " [1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.800     0.889         5\n",
      "           1      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.800         5\n",
      "   macro avg      0.500     0.400     0.444         5\n",
      "weighted avg      1.000     0.800     0.889         5\n",
      "\n",
      "k is 2\n",
      "[[4 0]\n",
      " [1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.800     0.889         5\n",
      "           1      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.800         5\n",
      "   macro avg      0.500     0.400     0.444         5\n",
      "weighted avg      1.000     0.800     0.889         5\n",
      "\n",
      "k is 3\n",
      "[[4 0]\n",
      " [1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.800     0.889         5\n",
      "           1      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.800         5\n",
      "   macro avg      0.500     0.400     0.444         5\n",
      "weighted avg      1.000     0.800     0.889         5\n",
      "\n",
      "k is 4\n",
      "[[4 0]\n",
      " [1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.800     0.889         5\n",
      "           1      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.800         5\n",
      "   macro avg      0.500     0.400     0.444         5\n",
      "weighted avg      1.000     0.800     0.889         5\n",
      "\n",
      "k is 5\n",
      "[[4 0]\n",
      " [1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.800     0.889         5\n",
      "           1      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.800         5\n",
      "   macro avg      0.500     0.400     0.444         5\n",
      "weighted avg      1.000     0.800     0.889         5\n",
      "\n",
      "k is 6\n",
      "[[4 0]\n",
      " [1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.800     0.889         5\n",
      "           1      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.800         5\n",
      "   macro avg      0.500     0.400     0.444         5\n",
      "weighted avg      1.000     0.800     0.889         5\n",
      "\n",
      "k is 7\n",
      "[[3 0]\n",
      " [2 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.600     0.750         5\n",
      "           1      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.600         5\n",
      "   macro avg      0.500     0.300     0.375         5\n",
      "weighted avg      1.000     0.600     0.750         5\n",
      "\n",
      "k is 8\n",
      "[[4 0]\n",
      " [1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.800     0.889         5\n",
      "           1      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.800         5\n",
      "   macro avg      0.500     0.400     0.444         5\n",
      "weighted avg      1.000     0.800     0.889         5\n",
      "\n",
      "k is 9\n",
      "[[4 0]\n",
      " [1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.800     0.889         5\n",
      "           1      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.800         5\n",
      "   macro avg      0.500     0.400     0.444         5\n",
      "weighted avg      1.000     0.800     0.889         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eliu0\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\eliu0\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\eliu0\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\eliu0\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\eliu0\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\eliu0\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\eliu0\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\eliu0\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\eliu0\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,10):\n",
    "    # Your code here\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    print(\"k is\", k)\n",
    "    print(confusion_matrix(y_test, pred).T)\n",
    "    print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like for classifying this dataset, `KNN` might not be the right approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6.6: An Application to Caravan Insurance Data\n",
    "Let's see how the `KNN` approach performs on the `Caravan` data set, which is\n",
    "part of the `ISLR` library. This data set includes 85 predictors that measure demographic characteristics for 5,822 individuals. The response variable is\n",
    "`Purchase`, which indicates whether or not a given individual purchases a\n",
    "caravan insurance policy. In this data set, only 6% of people purchased\n",
    "caravan insurance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     5474\n",
       "Yes     348\n",
       "Name: Purchase, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('../Data/Caravan.csv')\n",
    "df2[\"Purchase\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the `KNN` classifier predicts the class of a given test observation by\n",
    "identifying the observations that are nearest to it, the scale of the variables\n",
    "matters. Any variables that are on a large scale will have a much larger\n",
    "effect on the distance between the observations, and hence on the `KNN`\n",
    "classifier, than variables that are on a small scale. \n",
    "\n",
    "For instance, imagine a\n",
    "data set that contains two variables, salary and age (measured in dollars\n",
    "and years, respectively). As far as `KNN` is concerned, a difference of \\$1,000\n",
    "in salary is enormous compared to a difference of 50 years in age. Consequently,\n",
    "salary will drive the `KNN` classification results, and age will have\n",
    "almost no effect. \n",
    "\n",
    "This is contrary to our intuition that a salary difference\n",
    "of \\$1,000 is quite small compared to an age difference of 50 years. Furthermore,\n",
    "the importance of scale to the `KNN` classifier leads to another issue:\n",
    "if we measured salary in Japanese yen, or if we measured age in minutes,\n",
    "then we’d get quite different classification results from what we get if these\n",
    "two variables are measured in dollars and years.\n",
    "\n",
    "A good way to handle this problem is to **standardize** the data so that all\n",
    "variables are given a mean of zero and a standard deviation of one. Then\n",
    "all variables will be on a comparable scale. The `scale()` function from the `preprocessing` submodule of SciKitLearn does just\n",
    "this. In standardizing the data, we exclude column 86, because that is the\n",
    "qualitative `Purchase` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "y = df2.Purchase\n",
    "X = df2.drop('Purchase', axis=1).astype('float64')\n",
    "X_scaled = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now every column of `X_scaled` has a standard deviation of one and\n",
    "a mean of zero.\n",
    "\n",
    "We'll now split the observations into a test set, containing the first 1,000\n",
    "observations, and a training set, containing the remaining observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_scaled[1000:,:]\n",
    "y_train = y[1000:]\n",
    "\n",
    "X_test = X_scaled[:1000,:]\n",
    "y_test = y[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit a `KNN` model on the training data using $K = 1$, and evaluate its\n",
    "performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No      0.946     0.928     0.937       941\n",
      "         Yes      0.117     0.153     0.132        59\n",
      "\n",
      "    accuracy                          0.882      1000\n",
      "   macro avg      0.531     0.540     0.535      1000\n",
      "weighted avg      0.897     0.882     0.889      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN error rate on the 1,000 test observations is just under 12%. At first glance, this may appear to be fairly good. However, since only 6% of customers purchased insurance, we could get the error rate down to 6% by always predicting `No` regardless of the values of the predictors!\n",
    "\n",
    "Suppose that there is some non-trivial cost to trying to sell insurance\n",
    "to a given individual. For instance, perhaps a salesperson must visit each\n",
    "potential customer. If the company tries to sell insurance to a random\n",
    "selection of customers, then the success rate will be only 6%, which may\n",
    "be far too low given the costs involved. \n",
    "\n",
    "Instead, the company would like\n",
    "to try to sell insurance only to customers who are likely to buy it. So the\n",
    "overall error rate is not of interest. Instead, the fraction of individuals that\n",
    "are correctly predicted to buy insurance is of interest.\n",
    "\n",
    "It turns out that `KNN` with $K = 1$ does far better than random guessing\n",
    "among the customers that are predicted to buy insurance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[873  50]\n",
      " [ 68   9]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among 77 such\n",
    "customers, 9, or 11.7%, actually do purchase insurance. This is double the\n",
    "rate that one would obtain from random guessing. Let's see if increasing $K$ helps! Try out a few different $K$ values below. Feeling adventurous? Write a function that figures out the best value for $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k is 1\n",
      "[[873  50]\n",
      " [ 68   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No      0.946     0.928     0.937       941\n",
      "         Yes      0.117     0.153     0.132        59\n",
      "\n",
      "    accuracy                          0.882      1000\n",
      "   macro avg      0.531     0.540     0.535      1000\n",
      "weighted avg      0.897     0.882     0.889      1000\n",
      "\n",
      "k is 2\n",
      "[[932  59]\n",
      " [  9   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No      0.940     0.990     0.965       941\n",
      "         Yes      0.000     0.000     0.000        59\n",
      "\n",
      "    accuracy                          0.932      1000\n",
      "   macro avg      0.470     0.495     0.482      1000\n",
      "weighted avg      0.885     0.932     0.908      1000\n",
      "\n",
      "k is 3\n",
      "[[921  54]\n",
      " [ 20   5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No      0.945     0.979     0.961       941\n",
      "         Yes      0.200     0.085     0.119        59\n",
      "\n",
      "    accuracy                          0.926      1000\n",
      "   macro avg      0.572     0.532     0.540      1000\n",
      "weighted avg      0.901     0.926     0.912      1000\n",
      "\n",
      "k is 4\n",
      "[[936  59]\n",
      " [  5   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No      0.941     0.995     0.967       941\n",
      "         Yes      0.000     0.000     0.000        59\n",
      "\n",
      "    accuracy                          0.936      1000\n",
      "   macro avg      0.470     0.497     0.483      1000\n",
      "weighted avg      0.885     0.936     0.910      1000\n",
      "\n",
      "k is 5\n",
      "[[930  55]\n",
      " [ 11   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No      0.944     0.988     0.966       941\n",
      "         Yes      0.267     0.068     0.108        59\n",
      "\n",
      "    accuracy                          0.934      1000\n",
      "   macro avg      0.605     0.528     0.537      1000\n",
      "weighted avg      0.904     0.934     0.915      1000\n",
      "\n",
      "k is 6\n",
      "[[939  58]\n",
      " [  2   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No      0.942     0.998     0.969       941\n",
      "         Yes      0.333     0.017     0.032        59\n",
      "\n",
      "    accuracy                          0.940      1000\n",
      "   macro avg      0.638     0.507     0.501      1000\n",
      "weighted avg      0.906     0.940     0.914      1000\n",
      "\n",
      "k is 7\n",
      "[[936  57]\n",
      " [  5   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No      0.943     0.995     0.968       941\n",
      "         Yes      0.286     0.034     0.061        59\n",
      "\n",
      "    accuracy                          0.938      1000\n",
      "   macro avg      0.614     0.514     0.514      1000\n",
      "weighted avg      0.904     0.938     0.914      1000\n",
      "\n",
      "k is 8\n",
      "[[941  59]\n",
      " [  0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No      0.941     1.000     0.970       941\n",
      "         Yes      0.000     0.000     0.000        59\n",
      "\n",
      "    accuracy                          0.941      1000\n",
      "   macro avg      0.470     0.500     0.485      1000\n",
      "weighted avg      0.885     0.941     0.912      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenc/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k is 9\n",
      "[[941  58]\n",
      " [  0   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No      0.942     1.000     0.970       941\n",
      "         Yes      1.000     0.017     0.033        59\n",
      "\n",
      "    accuracy                          0.942      1000\n",
      "   macro avg      0.971     0.508     0.502      1000\n",
      "weighted avg      0.945     0.942     0.915      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "for k in range(1,10):\n",
    "    # Your code here\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    \n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    print(\"k is\", k)\n",
    "    print(confusion_matrix(y_test, pred).T)\n",
    "    print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that `KNN` is finding some real patterns in a difficult data set! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
